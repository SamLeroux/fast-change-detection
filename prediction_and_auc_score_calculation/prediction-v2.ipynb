{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 14.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.9.1\n",
      "  Downloading numpy-1.19.4-cp38-cp38-manylinux2010_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 43.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "\u001b[K     |████████████████████████████████| 269 kB 50.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.14\n",
      "  Downloading scipy-1.5.4-cp38-cp38-manylinux1_x86_64.whl (25.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.8 MB 50.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp38-cp38-linux_x86_64.whl size=44619 sha256=4b2e071a45fd508091da7a64a5892b6a24f017432b295da7df45024fc62ef921\n",
      "  Stored in directory: /home/hamer/.cache/pip/wheels/13/90/db/290ab3a34f2ef0b5a0f89235dc2d40fea83e77de84ed2dc05c\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: numpy, h5py, pyyaml, scipy, keras\n",
      "Successfully installed h5py-3.1.0 keras-2.4.3 numpy-1.19.4 pyyaml-5.3.1 scipy-1.5.4\n",
      "Collecting tensorflow-gpu==2.2\n",
      "  Downloading tensorflow_gpu-2.2.0-cp38-cp38-manylinux2010_x86_64.whl (516.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 516.3 MB 3.9 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow-gpu==2.2) (1.15.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.8/site-packages (from tensorflow-gpu==2.2) (0.35.1)\n",
      "Collecting tensorboard<2.3.0,>=2.2.0\n",
      "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 47.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.33.2-cp38-cp38-manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 46.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.8\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 11.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.7.0\n",
      "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 51.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting h5py<2.11.0,>=2.10.0\n",
      "  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 49.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.0\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 3.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0\n",
      "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
      "\u001b[K     |████████████████████████████████| 454 kB 49.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting protobuf>=3.8.0\n",
      "  Downloading protobuf-3.13.0-cp38-cp38-manylinux1_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 50.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy==1.4.1; python_version >= \"3\"\n",
      "  Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.0 MB 38.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow-gpu==2.2) (1.19.4)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 5.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "\u001b[K     |████████████████████████████████| 298 kB 50.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.23.0-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 52.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (49.6.0.post20201009)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 48.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (2.24.0)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 52.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.5\"\n",
      "  Downloading rsa-4.6-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 11.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu==2.2) (3.0.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 12.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: wrapt, termcolor\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=81739 sha256=d93973016701dacf0932ad07429aaf1a50f28c1f4e7eae9d0ea46c5574236097\n",
      "  Stored in directory: /home/hamer/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=efbe2a423b16ad6c6af22afe762cb194cbb6ffaf698fa13d04823f366aa10439\n",
      "  Stored in directory: /home/hamer/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built wrapt termcolor\n",
      "Installing collected packages: markdown, werkzeug, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, requests-oauthlib, google-auth-oauthlib, absl-py, protobuf, tensorboard-plugin-wit, grpcio, tensorboard, wrapt, google-pasta, h5py, keras-preprocessing, tensorflow-estimator, termcolor, scipy, astunparse, gast, opt-einsum, tensorflow-gpu\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.1.0\n",
      "    Uninstalling h5py-3.1.0:\n",
      "      Successfully uninstalled h5py-3.1.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.4\n",
      "    Uninstalling scipy-1.5.4:\n",
      "      Successfully uninstalled scipy-1.5.4\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.1.1 gast-0.3.3 google-auth-1.23.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.33.2 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.3.3 opt-einsum-3.3.0 protobuf-3.13.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.6 scipy-1.4.1 tensorboard-2.2.2 tensorboard-plugin-wit-1.7.0 tensorflow-estimator-2.2.0 tensorflow-gpu-2.2.0 termcolor-1.1.0 werkzeug-1.0.1 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow-gpu==2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /opt/conda/lib/python3.8/site-packages (0.23.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.19.4)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (1.1.4)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas) (2020.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.8/site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.8/site-packages (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /opt/conda/lib/python3.8/site-packages (from h5py) (1.19.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from h5py) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-plot in /opt/conda/lib/python3.8/site-packages (0.3.7)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from scikit-plot) (3.3.2)\n",
      "Requirement already satisfied: scipy>=0.9 in /opt/conda/lib/python3.8/site-packages (from scikit-plot) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.10 in /opt/conda/lib/python3.8/site-packages (from scikit-plot) (0.17.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /opt/conda/lib/python3.8/site-packages (from scikit-plot) (0.23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (8.0.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=1.4.0->scikit-plot) (1.19.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.18->scikit-plot) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dropout, Concatenate\n",
    "from keras.layers import AveragePooling2D, Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Cropping2D\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from IPython.display import Image, display\n",
    "import datetime\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from os import listdir\n",
    "import os, random, shutil\n",
    "from os.path import isfile, join\n",
    "from IPython.display import Image, display , clear_output\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "\n",
    "from IPython.display import Image, display , clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from scipy.misc import imread\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "\n",
    "import time\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate,Conv1D\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy.random as rng\n",
    "\n",
    "from keras.layers import Dropout, Concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import AveragePooling2D, Input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Cropping2D\n",
    "from keras.layers import MaxPooling2D, GlobalMaxPooling2D, GlobalMaxPooling1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "d9410f8b-c269-42e4-89db-61a7216d9206",
    "_uuid": "16af7f8c48a01c80759a167c8390841c04100778",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32410 images belonging to 2 classes.\n",
      "Found 3434 images belonging to 4 classes.\n",
      "Found 3434 images belonging to 4 classes.\n",
      "1013\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   vertical_flip = True,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(                                 )\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('data/Florida/day1_full/train/',\n",
    "                                                 target_size = (400, 225),\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('data/Florida/test_3096/',\n",
    "                                            target_size = (400, 225),\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode = 'binary')\n",
    "test_set2 = test_datagen.flow_from_directory('data/Florida/test_3096/',\n",
    "                                            target_size = (400, 225),\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "# generator= train_datagen.flow_from_directory(\"train\", batch_size=batch_size)\n",
    "# label_map = (generator.class_indices)\n",
    "\n",
    "img_height = 225\n",
    "img_width = 400\n",
    "dir1= 'data/Florida/day1_full/train/'\n",
    "# dir2= 'data/Florida/test_1/'\n",
    "dir2= 'data/Florida/test_3096/'\n",
    "\n",
    "\n",
    "input_imgen = ImageDataGenerator(#rescale = 1./255, \n",
    "                                   shear_range = 0.2, \n",
    "                                   zoom_range = 0.2,\n",
    "                                   rotation_range=5.,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_imgen = ImageDataGenerator(#rescale = 1./255\n",
    "                               )\n",
    "\n",
    "\n",
    "def generate_generator_multiple(generator,dir1, dir2, batch_size, img_height,img_width):\n",
    "    genX1 = generator.flow_from_directory(dir1,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'binary',\n",
    "                                          batch_size = batch_size\n",
    "                                         )\n",
    "    \n",
    "    genX2 = generator.flow_from_directory(dir2,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'binary',\n",
    "                                          batch_size = batch_size\n",
    "                                         )\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            yield [X1i[0], X2i[0]], X2i[1]  #Yield both images and their mutual label\n",
    "            \n",
    "            \n",
    "inputgenerator=generate_generator_multiple(generator=input_imgen,\n",
    "                                           dir1=dir1,\n",
    "                                           dir2=dir1,\n",
    "                                           batch_size=batch_size,\n",
    "                                           img_height=img_height,\n",
    "                                           img_width=img_width)       \n",
    "     \n",
    "testgenerator=generate_generator_multiple(test_imgen,\n",
    "                                          dir1=dir2,\n",
    "                                          dir2=dir2,\n",
    "                                          batch_size=batch_size,\n",
    "                                          img_height=img_height,\n",
    "                                          img_width=img_width)  \n",
    "\n",
    "     \n",
    "testgenerator1=generate_generator_multiple(test_imgen,\n",
    "                                          dir1=dir2,\n",
    "                                          dir2=dir2,\n",
    "                                          batch_size=batch_size,\n",
    "                                          img_height=img_height,\n",
    "                                          img_width=img_width)    \n",
    "\n",
    "steps_per_epoch =round(len(training_set))\n",
    "validation_steps =round(len(test_set))\n",
    "print(steps_per_epoch)\n",
    "print(validation_steps)\n",
    "\n",
    "# print(test_set.class_indices)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    \"\"\"\n",
    "        Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "# #################################\n",
    "    input_shape=(400, 225, 3)\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "\n",
    "    # Initialising the CNN    \n",
    "    # Convolutional Neural Network\n",
    "    model = Sequential()\n",
    "\n",
    "    # Step 1 - Convolution\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adding a second convolutional layer\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adding a third convolutional layer\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adding a fourth convolutional layer\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(GlobalMaxPooling2D())\n",
    "\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "#     keras.utils.plot_model(siamese_net, \"multi_input_and_output_model.png\", show_shapes=True)\n",
    "    # return the model\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    \"\"\"\n",
    "        Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "# #################################\n",
    "    input_shape=(400, 225, 3)\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    encoded_l = (left_input)\n",
    "    encoded_r = (right_input)\n",
    "    \n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "\n",
    "#     prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "\n",
    "\n",
    "    # Initialising the CNN    \n",
    "    # Convolutional Neural Network\n",
    "   # Step 1 - Convolution\n",
    "    x1= Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(L1_distance)\n",
    "    x1= BatchNormalization()(x1)\n",
    "    x1= MaxPooling2D(pool_size = (2, 2))(x1)\n",
    "    x1= Dropout(0.2)(x1)\n",
    "    # Adding a second convolutional layer\n",
    "    x1= Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x1)\n",
    "    x1= BatchNormalization()(x1)\n",
    "    x1= MaxPooling2D(pool_size = (2, 2))(x1)\n",
    "    x1= Dropout(0.2)(x1)\n",
    "    # Adding a third convolutional layer\n",
    "    x1= Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x1)\n",
    "    x1= BatchNormalization()(x1)\n",
    "    x1= MaxPooling2D(pool_size = (2, 2))(x1)\n",
    "    x1= Dropout(0.2)(x1)\n",
    "    # Adding a fourth convolutional layer\n",
    "    x1= Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x1)\n",
    "    x1= BatchNormalization()(x1)\n",
    "    x1= MaxPooling2D(pool_size = (2, 2))(x1)\n",
    "    x1= Dropout(0.2)(x1)\n",
    "    x1= GlobalMaxPooling2D()(x1)\n",
    "    x1= Dense(128, activation='relu', kernel_initializer='he_uniform')(x1)\n",
    "    x1= Dropout(0.5)(x1)\n",
    "    \n",
    "    x1=  Dense(1,activation='sigmoid')(x1)\n",
    "\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=x1)\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    keras.utils.plot_model(siamese_net, \"high.png\", show_shapes=True)\n",
    "    # return the model\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "# #################################\n",
    "    input_shape=(400, 225, 3)\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    x1 =  concatenate([left_input, right_input])\n",
    "    \n",
    "    # Step 1 - Convolution\n",
    "    x1= Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x1)\n",
    "    x1= BatchNormalization()(x1)\n",
    "    x1= MaxPooling2D(pool_size = (2, 2))(x1)\n",
    "    x1= Dropout(0.2)(x1)\n",
    "    # Adding a second convolutional layer\n",
    "    x1= Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x1)\n",
    "    x1= BatchNormalization()(x1)\n",
    "    x1= MaxPooling2D(pool_size = (2, 2))(x1)\n",
    "    x1= Dropout(0.2)(x1)\n",
    "    # Adding a third convolutional layer\n",
    "    x1= Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x1)\n",
    "    x1= BatchNormalization()(x1)\n",
    "    x1= MaxPooling2D(pool_size = (2, 2))(x1)\n",
    "    x1= Dropout(0.2)(x1)\n",
    "    # Adding a fourth convolutional layer\n",
    "    x1= Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same')(x1)\n",
    "    x1= BatchNormalization()(x1)\n",
    "    x1= MaxPooling2D(pool_size = (2, 2))(x1)\n",
    "    x1= Dropout(0.2)(x1)\n",
    "    x1= GlobalMaxPooling2D()(x1)\n",
    "    x1= Dense(128, activation='relu', kernel_initializer='he_uniform')(x1)\n",
    "    x1= Dropout(0.5)(x1)\n",
    "\n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction =  Dense(1,activation='sigmoid')(x1)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    model = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 400, 225, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 400, 225, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 128)          423232      input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 128)          0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         lambda[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 423,361\n",
      "Trainable params: 422,401\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_siamese_model((400, 225, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = SGD(lr=0.001, momentum=0.9)\n",
    "# model.compile(loss=\"binary_crossentropy\",optimizer=opt,metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1\n",
    "model.load_weights(\"weights_imported/siamese_4layers_day1_v1-epoch34.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 2\n",
    "model.load_weights(\"weights_imported/Siamese_network_high-embeddings-v2-epoch31.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3\n",
    "model.load_weights(\"weights_imported/two_inputs_high_concatenate-v1-epoch31.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64813\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "\n",
    "# list1 = (os.listdir(\"data/Florida/test_3096/change/\")) \n",
    "# # list2 = (os.listdir(\"data/Florida/test_3096/same/\")) \n",
    "\n",
    "# list2 = (os.listdir(\"data/Florida/test_3096/same_337/\")) ###############\n",
    "\n",
    "list1 = (os.listdir(\"data/Florida/test_set/change/\")) \n",
    "list2 = (os.listdir(\"data/Florida/test_set/same/\")) \n",
    "\n",
    "print(len(list1))\n",
    "print(len(list2))\n",
    "count=0\n",
    "j=0\n",
    "# while j<675:\n",
    "while j<64814:\n",
    "\n",
    "\n",
    "#     testnewset1 = (os.listdir(\"data/Florida/all_frames/\")) ###############\n",
    "#     testnewset1 = (os.listdir(\"data/Florida/new_all_frames/\")) \n",
    "    testnewset1 = (os.listdir(\"data/Florida/test_set/all_frames/\")) \n",
    "\n",
    "    testnewset_sorted1 = sorted(testnewset1) \n",
    "    res1 = testnewset_sorted1[j] \n",
    "#     res1 =Path(f'data/Florida/all_frames/{res1}').stem\n",
    "#    res1 =Path(f'data/Florida/new_all_frames/{res1}').stem\n",
    "#     res1 =Path(f'data/Florida/test_set/all_frames/{res1}').stem\n",
    "    res1 =Path(f'data/Florida/test_set/all_frames/{res1}').stem\n",
    "    \n",
    "#     print (\"The frame number is : \" +  str(res1)) \n",
    "#     print (\"The frame number is : \" +  str(res1),test_labels[j]) \n",
    "\n",
    "    test_img_path2= f'data/Florida/test_set/change/{res1}.jpg'\n",
    "    \n",
    "    test_samples.append(res1)\n",
    "\n",
    "#     print(test_img_path2)\n",
    "    if ( not os.path.isfile(test_img_path2)):\n",
    "        #same\n",
    "        label =[0]\n",
    "        test_labels.append(label)\n",
    "    else:\n",
    "#       #change\n",
    "        label =[1]\n",
    "        test_labels.append(label)\n",
    "\n",
    "    print(count)\n",
    "    count+=1\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    j+=1\n",
    "\n",
    "test_labels = (np.array(test_labels))\n",
    "# print(len(test_labels))\n",
    "# print(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Sample True labels\n",
      "0      2010202008000000000001           1\n",
      "1      2010202008000000000002           0\n",
      "2      2010202008000000000003           0\n",
      "3      2010202008000000000004           0\n",
      "4      2010202008000000000005           0\n",
      "...                       ...         ...\n",
      "64809  2010202017000000007196           0\n",
      "64810  2010202017000000007197           0\n",
      "64811  2010202017000000007198           0\n",
      "64812  2010202017000000007199           0\n",
      "64813  2010202017000000007200           0\n",
      "\n",
      "[64814 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "list = pd.DataFrame(np.column_stack([test_samples,test_labels ]), \n",
    "                               columns=['Sample', 'True labels'])\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frame number is : 2010202008000000000275.jpg\n",
      "The frame number is : 2010202008000000000276.jpg\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 5] Input/output error: 'data/Florida/test_set/all_frames/2010202008000000000275.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c760c996fefb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m64814\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#     preds = [int(np.round(result))]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-c760c996fefb>\u001b[0m in \u001b[0;36mfile\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mtest_image1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img_path1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m225\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mtest_image1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mtest_image1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: 'data/Florida/test_set/all_frames/2010202008000000000275.jpg'"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import os, random, shutil\n",
    "from os.path import isfile, join\n",
    "from IPython.display import Image, display , clear_output\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "global k\n",
    "\n",
    "def file():\n",
    "        j =0\n",
    "\n",
    "        while j <1:\n",
    "\n",
    "#             testnewset1 = (os.listdir(\"data/Florida/all_frames/\")) \n",
    "#             testnewset1 = (os.listdir(\"data/Florida/new_all_frames/\")) ##########\n",
    "            testnewset1 = (os.listdir(\"data/Florida/test_set/all_frames/\")) \n",
    "\n",
    "            testnewset_sorted1 = sorted(testnewset1) \n",
    "\n",
    "            res1 = testnewset_sorted1[k] \n",
    "            res2 = testnewset_sorted1[k+1] \n",
    "\n",
    "\n",
    "#             res2 =Path(f'data/Florida/all_frames/{res1}').stem\n",
    "#             res2 =Path(f'data/Florida/new_all_frames/{res1}').stem################################\n",
    "\n",
    "#             res2 = '%010d' % (int(res2[k]) )\n",
    "\n",
    "            print (\"The frame number is : \" +  str(res1)) \n",
    "            print (\"The frame number is : \" +  str(res2)) \n",
    "\n",
    "\n",
    "#             test_img_path1 = f\"data/Florida/all_frames/{res1}\"\n",
    "#             test_img_path2 = f\"data/Florida/all_frames/{res2}.jpg\"\n",
    "\n",
    "#             test_img_path1 = f\"data/Florida/new_all_frames/{res1}\" #########################\n",
    "#             test_img_path2 = f\"data/Florida/new_all_frames/{res2}\" #############################\n",
    "\n",
    "            test_img_path1 = f\"data/Florida/test_set/all_frames/{res1}\" #########################\n",
    "            test_img_path2 = f\"data/Florida/test_set/all_frames/{res2}\" #############################\n",
    "\n",
    "\n",
    "            test_image1 = image.load_img(test_img_path1, target_size = (400, 225))\n",
    "            test_image1 = image.img_to_array(test_image1)\n",
    "            test_image1 = np.expand_dims(test_image1, axis = 0)\n",
    "\n",
    "            test_image2 = image.load_img(test_img_path2, target_size = (400, 225))\n",
    "            test_image2 = image.img_to_array(test_image2)\n",
    "            test_image2 = np.expand_dims(test_image2, axis = 0)\n",
    "\n",
    "            j+=1\n",
    "\n",
    "        return test_image1,test_image2\n",
    "\n",
    "    \n",
    "test_all_frames=[]\n",
    "test_pred_labels=[]\n",
    "test_pred_labels_with_threshold=[]\n",
    "\n",
    "k=0\n",
    "#while k<675:\n",
    "while k<64814:\n",
    "\n",
    "    result = model.predict(file(),batch_size=1, verbose=1)\n",
    "    print(result)\n",
    "#     preds = [int(np.round(result))]\n",
    "#     print(preds)\n",
    "    preds = [float(result)]\n",
    "\n",
    "    test_pred_labels_with_threshold.append(preds)\n",
    "    \n",
    "    \n",
    "#     result = model.predict(file(),batch_size=1, verbose=1)\n",
    "#     print(result)\n",
    "    \n",
    "#     if result[0][0] > 0.45:\n",
    "#         prediction = [0]\n",
    "#     else:\n",
    "#         prediction = [1]\n",
    "\n",
    "#     print('prediction')\n",
    "#     print(prediction)\n",
    "#     print('rounded prediction')\n",
    "#     preds = [int(np.round(result))]\n",
    "#     print(preds)\n",
    "#     test_pred_labels.append(preds)\n",
    "#     test_pred_labels_with_threshold.append(prediction)\n",
    "\n",
    "    \n",
    "#     list3 = (os.listdir(\"data/Florida/all_frames/\")) \n",
    "#     list3 = (os.listdir(\"data/Florida/new_all_frames/\")) \n",
    "    list3 = (os.listdir(\"data/Florida/test_set/all_frames/\"))     \n",
    "\n",
    "    list3 = sorted(list3)\n",
    "    res3 = list3[k] \n",
    "    test_all_frames.append(res3)\n",
    "    k+=1\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# test_pred_labels = (np.array(test_pred_labels))\n",
    "\n",
    "\n",
    "# print(test_pred_labels)\n",
    "# print(test_pred_labels_with_threshold)\n",
    "\n",
    "# list = pd.DataFrame(np.column_stack([test_labels, test_pred_labels_with_threshold]), \n",
    "#                                columns=['real labels', 'predicted labels'])\n",
    "# print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_labels_with_threshold = (np.array(test_pred_labels_with_threshold))\n",
    "print(len(test_pred_labels_with_threshold))\n",
    "print(test_pred_labels_with_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "test_response = test_labels\n",
    "scores = test_pred_labels_with_threshold\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(test_response, scores)\n",
    "roc_auc = roc_auc_score(test_response, scores)\n",
    "print(\"AUC of ROC Curve:\", roc_auc)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frame number is : 0000003096.jpg\n",
      "The frame number is : 0000003100.jpg\n",
      "1/1 [==============================] - 0s 2ms/step\n",
      "[[0.46805578]]\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import os, random, shutil\n",
    "from os.path import isfile, join\n",
    "from IPython.display import Image, display , clear_output\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "global k\n",
    "\n",
    "def file():\n",
    "        j =0\n",
    "\n",
    "        while j <1:\n",
    "\n",
    "            testnewset1 = (os.listdir(\"data/Florida/all_frames/\")) \n",
    "\n",
    "            testnewset_sorted1 = sorted(testnewset1) \n",
    "\n",
    "            res1 = testnewset_sorted1[k] \n",
    "\n",
    "            res2 =Path(f'data/Florida/all_frames/{res1}').stem\n",
    "            res2 = '%010d' % (int(res2)+4 )\n",
    "\n",
    "            print (\"The frame number is : \" +  str(res1)) \n",
    "            print (\"The frame number is : \" +  str(res2)+\".jpg\") \n",
    "\n",
    "\n",
    "            test_img_path1 = f\"data/Florida/all_frames/{res1}\"\n",
    "            test_img_path2 = f\"data/Florida/all_frames/{res2}.jpg\"\n",
    "\n",
    "            test_image1 = image.load_img(test_img_path1, target_size = (400, 225))\n",
    "            test_image1 = image.img_to_array(test_image1)\n",
    "            test_image1 = np.expand_dims(test_image1, axis = 0)\n",
    "\n",
    "            test_image2 = image.load_img(test_img_path2, target_size = (400, 225))\n",
    "            test_image2 = image.img_to_array(test_image2)\n",
    "            test_image2 = np.expand_dims(test_image2, axis = 0)\n",
    "\n",
    "            j+=1\n",
    "\n",
    "        return test_image1,test_image2\n",
    "\n",
    "k=0\n",
    "while k<3096:\n",
    "    \n",
    "    result = model.predict(file(),batch_size=1, verbose=1)\n",
    "    print(result)\n",
    "    k+=1\n",
    "    clear_output(wait=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 328    9]\n",
      " [2725   34]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_true=test_labels, y_pred=test_pred_labels_with_threshold)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "cm_plot_labels = ['change','same']\n",
    "\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
